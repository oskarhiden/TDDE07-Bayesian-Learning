posterior_loglike = function(beta, y, X, mu, sigma){
nr_param = length(beta);
x_B = X%*%beta;
#loglike of
logL_like = sum( x_B*y -log(1 + exp(x_B)));
if (abs(log_like) == Inf) logLik = -20000; # constraint for logLike
# evaluating the prior
log_prior = dmvnorm(beta, matrix(0,nr_param,1), sigma, log=TRUE);
# add the log prior and log-likelihood together to get log posterior
return(log_like + log_prior)
}
#startvalues for beta vector
init_beta = rep(0,nr_param)
#Maximising loglike by changing beta
OptimResults<-optim(init_beta, posterior_loglike, gr=NULL,y,X,mu,sigma,method=c("BFGS"),control=list(fnscale=-1),hessian=TRUE)
x_B = T(X)%*%beta;
posterior_loglike = function(beta, y, X, mu, sigma){
nr_param = length(beta);
x_B = T(X)%*%beta;
#loglike of
logL_like = sum( x_B*y -log(1 + exp(x_B)));
if (abs(log_like) == Inf) logLik = -20000; # constraint for logLike
# evaluating the prior
log_prior = dmvnorm(beta, matrix(0,nr_param,1), sigma, log=TRUE);
# add the log prior and log-likelihood together to get log posterior
return(log_like + log_prior)
}
#startvalues for beta vector
init_beta = rep(0,nr_param)
#Maximising loglike by changing beta
OptimResults<-optim(init_beta, posterior_loglike, gr=NULL,y,X,mu,sigma,method=c("BFGS"),control=list(fnscale=-1),hessian=TRUE)
posterior_loglike = function(beta, y, X, mu, sigma){
nr_param = length(beta);
x_B = t(X)%*%beta;
#loglike of
logL_like = sum( x_B*y -log(1 + exp(x_B)));
if (abs(log_like) == Inf) logLik = -20000; # constraint for logLike
# evaluating the prior
log_prior = dmvnorm(beta, matrix(0,nr_param,1), sigma, log=TRUE);
# add the log prior and log-likelihood together to get log posterior
return(log_like + log_prior)
}
#startvalues for beta vector
init_beta = rep(0,nr_param)
#Maximising loglike by changing beta
OptimResults<-optim(init_beta, posterior_loglike, gr=NULL,y,X,mu,sigma,method=c("BFGS"),control=list(fnscale=-1),hessian=TRUE)
x_B = t(X)%*%init_beta;
View(x_B)
View(x_B)
y = data.matrix(women[,1])
X = data.matrix(women[,-1])
# 3a
women = read.table("/Users/oskarhiden/Git/TDDE07 Bayesian Learning/Lab 2/WomenWork.txt")
women_names = women[1, ]
women = women[-1,]
y = data.matrix(women[,1])
X = data.matrix(women[,-1])
# 3a
women = read.table("/Users/oskarhiden/Git/TDDE07 Bayesian Learning/Lab 2/WomenWork.txt")
women_names = women[1, ]
women = women[-1,]
y = data.matrix(women[,1])
X = data.matrix(women[,-1])
women = as.numeric(women[-1,])
View(women)
View(women)
# 3a
women = read.table("/Users/oskarhiden/Git/TDDE07 Bayesian Learning/Lab 2/WomenWork.dat")
View(women)
View(women)
women_names = women[1, ]
women = as.numeric(women[-1,])
y = data.matrix(women[,1])
X = data.matrix(women[,-1])
nr_param = length(y)
# Prior values
mu = rep(0, nr_param)
tau = 10
sigma = tau^2*diag(nr_param)
# 3a
women = read.table("/Users/oskarhiden/Git/TDDE07 Bayesian Learning/Lab 2/WomenWork.dat", header = TRUE)
View(women)
View(women)
y = as.vector(women[,1])
X = as.matrix(women[,-1])
nr_param = length(y)
# Prior values
mu = rep(0, nr_param)
tau = 10
sigma = tau^2*diag(nr_param)
posterior_loglike = function(beta, y, X, mu, sigma){
nr_param = length(beta)
x_B = t(X)%*%beta
#loglike of
logL_like = sum( x_B*y -log(1 + exp(x_B)))
if (abs(log_like) == Inf) logLik = -20000 # constraint for logLike
# evaluating the prior
log_prior = dmvnorm(beta, matrix(0,nr_param,1), sigma, log=TRUE)
# add the log prior and log-likelihood together to get log posterior
return(log_like + log_prior)
}
#startvalues for beta vector
init_beta = rep(0,nr_param)
#Maximising loglike by changing beta
OptimResults<-optim(init_beta, posterior_loglike, gr=NULL,y,X,mu,sigma,method=c("BFGS"),control=list(fnscale=-1),hessian=TRUE)
x_B = t(X)%*%init_beta;
?optim
#startvalues for beta vector
init_beta = as.vector(rep(0,nr_param))
#Maximising loglike by changing beta
OptimResults<-optim(init_beta, posterior_loglike, gr=NULL,y,X,mu,sigma,method=c("BFGS"),control=list(fnscale=-1),hessian=TRUE)
#Maximising loglike by changing beta
Optim_results<-optim(init_beta, posterior_loglike, gr=NULL,y,X,mu,sigma,method=c("BFGS"),control=list(fnscale=-1),hessian=TRUE)
nr_param = length(X[1,])
# Prior values
mu = rep(0, nr_param)
tau = 10
sigma = tau^2*diag(nr_param)
posterior_loglike = function(beta, y, X, mu, sigma){
nr_param = length(beta)
x_B = t(X)%*%beta
#loglike of
logL_like = sum( x_B*y -log(1 + exp(x_B)))
if (abs(log_like) == Inf) logLik = -20000 # constraint for logLike
# evaluating the prior
log_prior = dmvnorm(beta, matrix(0,nr_param,1), sigma, log=TRUE)
# add the log prior and log-likelihood together to get log posterior
return(log_like + log_prior)
}
#startvalues for beta vector
init_beta = as.vector(rep(0,nr_param))
#Maximising loglike by changing beta
Optim_results<-optim(init_beta, posterior_loglike, gr=NULL,y,X,mu,sigma,method=c("BFGS"),control=list(fnscale=-1),hessian=TRUE)
posterior_loglike = function(beta, y, X, mu, sigma){
nr_param = length(beta)
x_B = X%*%beta
#loglike of
logL_like = sum( x_B*y -log(1 + exp(x_B)))
if (abs(log_like) == Inf) logLik = -20000 # constraint for logLike
# evaluating the prior
log_prior = dmvnorm(beta, matrix(0,nr_param,1), sigma, log=TRUE)
# add the log prior and log-likelihood together to get log posterior
return(log_like + log_prior)
}
#startvalues for beta vector
init_beta = as.vector(rep(0,nr_param))
#Maximising loglike by changing beta
Optim_results<-optim(init_beta, posterior_loglike, gr=NULL,y,X,mu,sigma,method=c("BFGS"),control=list(fnscale=-1),hessian=TRUE)
posterior_loglike = function(beta, y, X, mu, sigma){
nr_param = length(beta)
x_B = X%*%beta
#loglike of
log_like = sum( x_B*y -log(1 + exp(x_B)))
if (abs(log_like) == Inf) logLik = -20000 # constraint for logLike
# evaluating the prior
log_prior = dmvnorm(beta, matrix(0,nr_param,1), sigma, log=TRUE)
# add the log prior and log-likelihood together to get log posterior
return(log_like + log_prior)
}
#startvalues for beta vector
init_beta = as.vector(rep(0,nr_param))
#Maximising loglike by changing beta
Optim_results<-optim(init_beta, posterior_loglike, gr=NULL,y,X,mu,sigma,method=c("BFGS"),control=list(fnscale=-1),hessian=TRUE)
Optim_results$hessian
solve(Optim_results$hessian)
#Result
postMode <- optim_results$par
#Maximising loglike by changing beta
optim_results<-optim(init_beta, posterior_loglike, gr=NULL,y,X,mu,sigma,method=c("BFGS"),control=list(fnscale=-1),hessian=TRUE)
#Result
postMode <- optim_results$par
postCov <- -solve(OptimResults$hessian) # Posterior covariance matrix is -inv(Hessian)
postCov <- -solve(optim_results$hessian) # Posterior covariance matrix is -inv(Hessian)
?solve
post_cov = solve(j_y)
j_y = -optim_results$hessian # Posterior covariance matrix is -inv(Hessian)
post_cov = solve(j_y)
?optim
View(women)
View(women)
#nSmallChild = idex 7
b_sc = post_beta[7]
#Result
post_beta = optim_results$par
j_y = -optim_results$hessian # Posterior covariance matrix is -inv(Hessian)
post_cov = solve(j_y) #inverse
#nSmallChild = idex 7
b_sc = post_beta[7]
simga2_sc = post_cov[7,7]
?norm
?rnorm
#draw from nrom
draws = rnorm(b_sc, sigma2_sc)
sigma2_sc = post_cov[7,7]
#draw from nrom
draws = rnorm(b_sc, sigma2_sc)
sigma2_sc = post_cov[7,7]
#draw from nrom
draws = rnorm(b_sc, sigma2_sc)
#draw from nrom
draws = rnorm(10000, b_sc, sigma2_sc)
draws
#draw from nrom
draws_sc = rnorm(10000, b_sc, sigma2_sc)
draws_sc
quantile_sc = apply(draws_sct,2,quantile, probs=c(0.025,0.975))
quantile_sc = apply(draws_sc,2,quantile, probs=c(0.025,0.975))
#draw from nrom
draws_sc = rnorm(10000, b_sc, sigma2_sc)
draws_sc
quantile_sc = apply(draws_sc,2,quantile, probs=c(0.025,0.975))
?apply(array, margin, ...)
#draw from nrom
draws_sc = rnorm(1000, b_sc, sigma2_sc)
draws_sc
quantile_sc = apply(draws_sc,2,quantile, probs=c(0.025,0.975))
?rnorm
quantile_sc = apply(draws_sc,2,quantile, probs=c(0.025,0.975))
quantile_sc = apply(draws_sc,2,quantile, probs=c(0.025,0.975))
#draw from nrom
quantile_sc = dnorm(c(0.025,0.975), b_sc, sigma2_sc)
quantile_sc
?mtvnorm
?mvtnormÂ¨
?mvtnorm
?mvtnorm
#2c
library(mvtnorm)
?mvtnorm
?dmvnorm
View(X)
View(X)
X_pred = c(1, husband_inc, years_ed, years_exp, (years_exp/10)^2, age, nr_small_ch, nr_big_ch )
#Predicting for
husband_inc = 10
years_ed = 8
years_exp = 10
age = 40
nr_small_ch = 1
nr_big_ch = 1
X_pred = c(1, husband_inc, years_ed, years_exp, (years_exp/10)^2, age, nr_small_ch, nr_big_ch )
#draw beta from posterior
nr_draws = 100
beta_draws = rmvnorm(100, post_beta, post_cov)
#draw beta from posterior
nr_draws = 100
beta_draws = rmvnorm(100, post_beta, post_cov)
#draw beta from posterior
nr_draws = 100
beta_draws = rmvnorm(100, post_beta, post_cov)
exp_xb = exp(X_pred%*%beta_draws)
pred_y_given_x = exp_xb/(1+exp_xb)
exp_xb = exp(X_pred%*%beta_draws)
exp_xb = exp(t(X_pred)%*%beta_draws)
X_pred = as.vector(c(1, husband_inc, years_ed, years_exp, (years_exp/10)^2, age, nr_small_ch, nr_big_ch ))
#draw beta from posterior
nr_draws = 100
beta_draws = rmvnorm(100, post_beta, post_cov)
exp_xb = exp(t(X_pred)%*%beta_draws)
pred_y_given_x = exp_xb/(1+exp_xb)
exp_xb = exp(X_pred%*%beta_draws)
X_pred = c(1, husband_inc, years_ed, years_exp, (years_exp/10)^2, age, nr_small_ch, nr_big_ch )
#draw beta from posterior
nr_draws = 100
beta_draws = rmvnorm(100, post_beta, post_cov)
exp_xb = exp(X_pred%*%beta_draws)
pred_y_given_x = exp_xb/(1+exp_xb)
exp_xb = exp(X_pred%*%t(beta_draws))
pred_y_given_x = exp_xb/(1+exp_xb)
hist(pred_y_given_x)
?rbinom
pred = rbinom(nr_draws, 10, beta_draws)
pred = rbinom(nr_draws/10, 10, beta_draws)
beta_draws
#2c
nr_draws = 100
nr_draws=nr_draws*10
beta_draws = rmvnorm(100, post_beta, post_cov)
beta_draws
pred = rbinom(nr_draws/10, 10, beta_draws)
beta_draws = rmvnorm(nr_draws, post_beta, post_cov)
beta_draws
pred = rbinom(nr_draws/10, 10, beta_draws)
beta_draws = rmvnorm(nr_draws, post_beta, post_cov)
beta_draws
pred = rbinom(nr_draws/10, 10, beta_draws)
pred
pred = rbinom(1, 10, beta_draws)
pred
beta_draws
abs(beta_draws)
beta_draws = abs(beta_draws)
pred = rbinom(1, 10, beta_draws)
pred
beta_draws = abs(beta_draws)
pred = rbinom(1, 10, beta_draws)
pred
exp_xb
exp_xb = exp(X_pred%*%t(beta_draws))
pred_y_given_x = exp_xb/(1+exp_xb)
hist(pred_y_given_x)
beta_draws = rmvnorm(nr_draws*10, post_beta, post_cov)
exp_xb = exp(X_pred%*%t(beta_draws))
pred_y_given_x = exp_xb/(1+exp_xb)
pred = rbinom(1, 10, pred_y_given_x)
pred
pred = rbinom(nr_draws, 10, pred_y_given_x)
pred
#2c
nr_draws = 100
beta_draws = rmvnorm(nr_draws*10, post_beta, post_cov)
exp_xb = exp(X_pred%*%t(beta_draws))
pred_y_given_x = exp_xb/(1+exp_xb)
pred = rbinom(nr_draws, 10, pred_y_given_x)
pred
pred = rbinom(nr_draws, 10, pred_y_given_x)
pred = rbinom(nr_draws, 10, pred_y_given_x)
pred = rbinom(nr_draws, 10, pred_y_given_x)
hist(pred)
hist(pred)
#2c
nr_draws = 100
beta_draws = rmvnorm(nr_draws*10, post_beta, post_cov)
exp_xb = exp(X_pred%*%t(beta_draws))
pred_y_given_x = exp_xb/(1+exp_xb)
pred = rbinom(nr_draws, 10, pred_y_given_x)
hist(pred)
#2b
library(mvtnorm)
#Predicting for
husband_inc = 10
years_ed = 8
years_exp = 10
age = 40
nr_small_ch = 1
nr_big_ch = 1
X_pred = c(1, husband_inc, years_ed, years_exp, (years_exp/10)^2, age, nr_small_ch, nr_big_ch )
#draw beta from posterior
nr_draws = 100
beta_draws = rmvnorm(100, post_beta, post_cov)
exp_xb = exp(X_pred%*%t(beta_draws))
pred_y_given_x = exp_xb/(1+exp_xb)
hist(pred_y_given_x)
pred = rbinom(nr_draws, 10, pred_y_given_x)
hist(pred)
?rbinom
pred = rbinom(nr_draws, 10, c(0.1, 0.2))
hist(pred)
set.seed(12345)
pred = rbinom(nr_draws, 10, pred_y_given_x)
pred
set.seed(12345)
allPredictions=c(0)
for (i in yPredictions) {
allPredictions=cbind(allPredictions,rbinom(1,10,pred_y_given_x))
}
set.seed(12345)
allPredictions=c(0)
for (i in pred_y_given_x) {
allPredictions=cbind(allPredictions,rbinom(1,10,i))
}
allPredictions
set.seed(12345)
allPredictions=c()
for (i in pred_y_given_x) {
allPredictions=cbind(allPredictions,rbinom(1,10,i))
}
allPredictions
allPredictions=as.vector(c())
for (i in pred_y_given_x) {
allPredictions=cbind(allPredictions,rbinom(1,10,i))
}
allPredictions
pred
set.seed(12345)
allPredictions=as.vector(c())
for (i in pred_y_given_x) {
allPredictions=cbind(allPredictions,rbinom(1,10,i))
}
allPredictions
hits(allPredictions)
hist(allPredictions)
hist(pred)
#1c
x_hat = which.max(y_median)
y_median[x_hat]
data = read.table("/Users/oskarhiden/Git/TDDE07 Bayesian Learning/Lab 2/TempLinkoping.txt")
time = as.numeric(as.vector(data[-1,1]))
temp = as.numeric(as.vector(data[-1,2]))
# 1a)
mu_0 = c(-10, 100, -100)
omega_0 = 0.01*diag(3)
omega_0_inv = 100*diag(3)
v_0 = 4
sigma_0_2 = 1
#draws sigma 2
nr_draws = 100
x_draws = rchisq(nr_draws,v_0)
sigma2_draws = ((v_0)*sigma_0_2)/x_draws
#draws beta given simga
library(mvtnorm)
betas = matrix(, nrow=nr_draws, ncol=3)
for (i in 1:nr_draws) {
covar = sigma2_draws[i]*omega_0_inv
betas[i,] = rmvnorm(1, mu_0, covar)
}
betas
A = rep(1, length(time))
B = time
C = time^2
x = cbind(A, B, C) #beta order B0, B1, B2
x
t(x)
y_draws = betas%*%t(x)
y_draws
#draw predictions
plot(time*365, y_draws[1,], type = "l", ylim = c(-60,70))
for (i in 2:nr_draws) {
points( y_draws[i,], type="l")
}
# hottest in the summer
#1b
#posterior
library(matlib)
beta_hat = inv( t(x)%*%x ) %*% (t(x)%*%temp)
mu_n = inv( t(x)%*%x+omega_0 )%*%( t(x)%*%x%*%beta_hat + omega_0%*%mu_0)
omega_n = t(x)%*%x+omega_0
v_n = v_0 + length(time)
sigma_n_2 = (v_0*sigma_0_2 + (t(temp)%*%temp + t(mu_0)%*%omega_0%*%mu_0 - t(mu_n)%*%omega_n%*%mu_n))/v_n
#draw sigma2
nr_draws = 100
sigma_draws = rchisq(nr_draws,v_n)
sigma2_draws = ((v_n)*sigma_n_2)/sigma_draws
betas_post = matrix(, nrow=nr_draws, ncol=3)
for (i in 1:nr_draws) {
covar = sigma2_draws[i]*inv(omega_n)
betas_post[i,] = rmvnorm(1, mu_n, covar)
}
#plot hist of beta and sigma
hist(sigma2_draws, breaks = 50)
hist(betas[,1], breaks = 50)
hist(betas[,2], breaks = 50)
hist(betas[,3], breaks = 50)
# calculate y, predicted temp for all draws
y_post = betas_post%*%t(x)
y_post
#Calculate mean for y each day form all predictions
#y_mean = colMeans(y_post)
y_median = apply(y_post,2,median)
plot(temp, col="blue")
points(time*365, y_median, type="l")
#curves for 95% equal tail
#sorted_y_post = sort(y_psot)
sorted_y_post = apply(y_post,2,sort,decreasing=F)
points(sorted_y_post[round(nr_draws*0.025),], type="l", col="red")
points(sorted_y_post[round(nr_draws*0.975),], type="l", col="red")
quantile_y_post = apply(y_post,2,quantile, probs=c(0.025,0.975))
points(quantile_y_post[1,], col="green", type="l")
points(quantile_y_post[2,], col="green", type="l")
# The posterior probability intevall showes us were our real model would be wthin wiht 95% credability. (from beta)
# It does not show were the actual y is by 95% credability.
#1c
x_hat = which.max(y_median)
y_median[x_hat]
#From previous data
all_hot_days = apply(y_post, 1, which.max)
all_hot_days
hist(all_hot_days, breaks=10)
#from derivation
all_hot_days2 = (-betas_post[,2]/(2*betas_post[,3]))*365
all_hot_days2
hit(all_hot_days2)
hist(all_hot_days2)
#From previous data
all_hot_days = apply(y_post, 1, which.max)
all_hot_days
hist(all_hot_days, breaks=10)
#from derivation
all_hot_days2 = (-betas_post[,2]/(2*betas_post[,3]))*365
hist(all_hot_days2)
# 2a
women = read.table("/Users/oskarhiden/Git/TDDE07 Bayesian Learning/Lab 2/WomenWork.dat", header = TRUE)
#From previous data
all_hot_days = apply(y_post, 1, which.max)
all_hot_days
hist(all_hot_days, breaks=10)
#from derivation
all_hot_days2 = (-betas_post[,2]/(2*betas_post[,3]))*365
hist(all_hot_days2)
knitr::opts_chunk$set(echo = TRUE)
y_median[x_hat]
library(matlib)
beta_hat = inv( t(x)%*%x ) %*% (t(x)%*%temp)
mu_n = inv( t(x)%*%x+omega_0 )%*%( t(x)%*%x%*%beta_hat + omega_0%*%mu_0)
omega_n = t(x)%*%x+omega_0
v_n = v_0 + length(time)
sigma_n_2 = (v_0*sigma_0_2 + (t(temp)%*%temp + t(mu_0)%*%omega_0%*%mu_0 - t(mu_n)%*%omega_n%*%mu_n))/v_n
#draw sigma2
nr_draws = 100
sigma_draws = rchisq(nr_draws,v_n)
sigma2_draws = ((v_n)*sigma_n_2)/sigma_draws
betas_post = matrix(, nrow=nr_draws, ncol=3)
for (i in 1:nr_draws) {
covar = sigma2_draws[i]*inv(omega_n)
betas_post[i,] = rmvnorm(1, mu_n, covar)
}
#plot hist of beta and sigma
hist(sigma2_draws, breaks = 50)
hist(betas[,1], breaks = 50)
hist(betas[,2], breaks = 50)
hist(betas[,3], breaks = 50)
sigma2_draws = (v_n*sigma_n_2)/sigma_draws
